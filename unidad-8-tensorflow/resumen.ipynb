{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow es una plataforma desarrollada por google que facilita el desarrollo y mantenimiento de modelos de ML.\n",
    "\n",
    "La arquitectura de TensorFlow tiene varios niveles de abstracción:\n",
    "- En su primer nivel, su base, está su codigo de base en C++, ue realizará la mayor parte de los calculos\n",
    "- Luego le sigue un nivel de de abstraccion que permite la invocacion del codigo C++ con python\n",
    "- Finalmente, la tercera capa esta compuesta por:\n",
    "    1. `Keras`: una biblioteca que permite el facil desarrollo de modelos de redes neuronales\n",
    "    2. `Estimator`: una biblioteca con multiples plantillas o componentes prefabricados que permiten construir facilmente modelos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TensorFlow` vs. `Sklearn`\n",
    "\n",
    "| TensorFlow | Sklearn |\n",
    "| ---------- | ------- |\n",
    "| Su base en C++ permite utilizar grandes sets de datos de forma eficiente <ul><li>Permite la utilizacion de las tarjetas graficas para el <br> computo / entrenamiento de los modelos</li></ul> | Set de datos relativamente pequeños |\n",
    "| Curva de aprendizaje alta | Curva de aprendizaje baja |\n",
    "| Desarrollada tanto para Python como para JavaScript | Biblioteca de Python |\n",
    "| Expone una mayor cantidad de parametros de configuracion para los modelos | <ul><li>Cantidad de entradas</li><li>Canitdad de capas ocultas</li><li>Cantidad de iteraciones</li></ul>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabajar con TensorFlow debemos utilizar \"Tensores\".\n",
    "\n",
    "Los tensores son arrays multidimensionales de un tipo uniforme de dato. Son muy parecidos a los arrays de NumPy, pero con la ventaja de que son mucho mas eficientes y son capaces de ser utilizados en la memoria de las targetas graficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tensor cuyo valor no cambia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([1, 2, 3], dtype=tf.float32, name='una_constante')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lo definimos indicando:\n",
    "    - Su valor\n",
    "    - Su tipo de dato\n",
    "    - Su nombre (_opcional_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tensor cuyo valor puede cambiar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'una_variable:0' shape=() dtype=float32, numpy=3.0>\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(3, dtype=tf.float32, name='una_variable')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lo definimos utilizando los mismos parametros que para las constantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reasignar su valor con `assign()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'una_variable:0' shape=() dtype=float32, numpy=10.0>\n"
     ]
    }
   ],
   "source": [
    "v.assign(10)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El valor asignado debe ser del mismo tipo y forma (`shape`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensores y NumPy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos convertir arrays de NumPy en tensores constantes utilizando `convert_to_tensor()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "array = np.array([1,2,3])\n",
    "tensor = tf.convert_to_tensor(array, tf.int32)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Debemos indicarle el tipo de dato a utilizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto funciona para arrays de cualquier forma y numero de dimensiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]], shape=(2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "array2D = np.array([\n",
    "    [1,2,3,4],\n",
    "    [5,6,7,8]\n",
    "])\n",
    "\n",
    "tensor2D = tf.convert_to_tensor(array2D, tf.int32)\n",
    "print(tensor2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego tambien podemos convertir tensores en arrays de NumPy con `numpy()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2D.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz vacia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos construir matrices de ceros de cualquier forma sin necesidad de utilizar NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]], shape=(5, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "matrix0 = tf.zeros((5,5), tf.int32, name=\"matriz_ceros\")\n",
    "print(matrix0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Indicamos la forma\n",
    "- y el tipo de dato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trabajando con tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde la version 2.0 de TensorFlow podemos trabajar con los tensores commo lo hariamos con cualquier otro array de numpy.\n",
    "\n",
    "Anteriormente, para trabajar con tensores debiamos inicializarlos y ejecutarlos en el contexto de una `Session` utilizando su metodo `session.run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[4]\n",
      " [5]\n",
      " [6]], shape=(3, 1), dtype=int32)\n",
      "\n",
      "Constant mult:\n",
      "t1 * t2 = [[2 4 6]]\n",
      "\n",
      "Constant division:\n",
      "t3 / t1 =\n",
      "[[2. ]\n",
      " [2.5]\n",
      " [3. ]]\n",
      "\n",
      "Matrix mult:\n",
      "t2 x t3 =\n",
      "[[32]]\n",
      "\n",
      "etc...\n"
     ]
    }
   ],
   "source": [
    "t1 = tf.constant(2, name=\"t1\")\n",
    "t2 = tf.constant([[1,2,3]], name=\"t2\")\n",
    "t3 = tf.constant([[4], [5], [6]], name=\"t3\")\n",
    "\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(\"\\nConstant mult:\")\n",
    "print(f\"t1 * t2 = {t1 * t2}\")\n",
    "print(\"\\nConstant division:\")\n",
    "print(f\"t3 / t1 =\\n{t3 / t1}\")\n",
    "print(\"\\nMatrix mult:\")\n",
    "print(f\"t2 x t3 =\\n{t2 @ t3}\")\n",
    "print(\"\\netc...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de aplicación: *clasificacion de texto*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo clasificaremos la reseñas de varias peliculas como positivas o negativas. Para ello tomaremos los datos del dataset `imdb` de `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "S:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "S:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "imdb = keras.datasets.imdb\n",
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos ya vienen pre-procesados de forma tal que cada reseña (secuencias de palabras) se han convertido en secuencias de numeros enteros que representan, cada uno, una palabra especifica dentro de un diccionario generado a partir del parametro `num_words` (el numero de palabras del diccionario).\n",
    "\n",
    "El diccionario mantiene las N palabras que aparecen con mayor frecuencia en los datos: Las palabras raras (poco frecuentes) fueron descartadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseña 0:\n",
      "Primeros 10 indices: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
      "Indices totales: 218\n"
     ]
    }
   ],
   "source": [
    "print(\"Reseña 0:\")\n",
    "print(f\"Primeros 10 indices: {train_data[0][:10]}\")\n",
    "print(f\"Indices totales: {len(train_data[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para convertir la secuencia de numeros enteros de nuevo a palabras utilizamos `get_word_index()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = { word: index+3 for word, index in imdb.get_word_index().items() }\n",
    "# Reservamos los primeros 3 indices para palabras especiales\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2 # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = { index: word for word, index in word_index.items() }\n",
    "\n",
    "def decode_review(review_indices):\n",
    "    return ' '.join([reverse_word_index[index] for index in review_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto para la reseña 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos convertir estas secuencias de enteros en tensores para poder alimentarlos a la red neuronal.\n",
    "\n",
    "Es importante notar que cada reseña tiene un tamaño distinto, por lo tanto, al mismo tiempo vamos a querer transformarlas para que todas tengan el mismo tamaño.\n",
    "- El input de nuestra red tiene que ser siempre del mismo tamaño\n",
    "\n",
    "Esto lo logramos utilizando `keras.preprocessing.sequence.pad_sequences()` que rellena con un determinado valor las secuencias de caracteres que tengan un tamaño menor al maximo dado, y truncan aquellas con un tamaño mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25000, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def pad_data(data_array):\n",
    "    MAX_LEN = 256\n",
    "    padded_array = pad_sequences(data_array, value=word_index[\"<PAD>\"], maxlen=MAX_LEN, padding=\"post\")\n",
    "    return tf.convert_to_tensor(padded_array)\n",
    "\n",
    "padded_train_data = pad_data(train_data)\n",
    "padded_test_data = pad_data(test_data)\n",
    "\n",
    "padded_train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 25000 reseñas de 256 palabras cada una\n",
    "- El parametro `maxlen`, en este caso, es un valor arbitrario que vamos a tomar para este ejemplo\n",
    "    - Vamos a utilizar reseñas de 256 palabras\n",
    "    - Si no se especifica, el valor por default es el de la frase / reseña más larga\n",
    "- El parametro `padding` indica si agregar el valor al principio o al final de vector\n",
    "    - Puede ser tanto \"post\" (al final) o \"pre\" (al principio), este es el default\n",
    "    - Analogamente existe un parametro `truncating` que indica que valores sobrantes truncar, los del principio o los del final\n",
    "        - Por default es \"pre\" y lo vamos a dejar así para este ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver el padding en la primer reseña:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256,), dtype=int32, numpy=\n",
       "array([   1,   14,   22,   16,   43,  530,  973, 1622, 1385,   65,  458,\n",
       "       4468,   66, 3941,    4,  173,   36,  256,    5,   25,  100,   43,\n",
       "        838,  112,   50,  670,    2,    9,   35,  480,  284,    5,  150,\n",
       "          4,  172,  112,  167,    2,  336,  385,   39,    4,  172, 4536,\n",
       "       1111,   17,  546,   38,   13,  447,    4,  192,   50,   16,    6,\n",
       "        147, 2025,   19,   14,   22,    4, 1920, 4613,  469,    4,   22,\n",
       "         71,   87,   12,   16,   43,  530,   38,   76,   15,   13, 1247,\n",
       "          4,   22,   17,  515,   17,   12,   16,  626,   18,    2,    5,\n",
       "         62,  386,   12,    8,  316,    8,  106,    5,    4, 2223, 5244,\n",
       "         16,  480,   66, 3785,   33,    4,  130,   12,   16,   38,  619,\n",
       "          5,   25,  124,   51,   36,  135,   48,   25, 1415,   33,    6,\n",
       "         22,   12,  215,   28,   77,   52,    5,   14,  407,   16,   82,\n",
       "          2,    8,    4,  107,  117, 5952,   15,  256,    4,    2,    7,\n",
       "       3766,    5,  723,   36,   71,   43,  530,  476,   26,  400,  317,\n",
       "         46,    7,    4,    2, 1029,   13,  104,   88,    4,  381,   15,\n",
       "        297,   98,   32, 2071,   56,   26,  141,    6,  194, 7486,   18,\n",
       "          4,  226,   22,   21,  134,  476,   26,  480,    5,  144,   30,\n",
       "       5535,   18,   51,   36,   28,  224,   92,   25,  104,    4,  226,\n",
       "         65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,\n",
       "        113,  103,   32,   15,   16, 5345,   19,  178,   32,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos los datos de entrada del modelo listos, podemos pensar en el diseño del modelo.\n",
    "\n",
    "Vamos a definir un modelo de red neuronal con las siguientes capas:\n",
    "1. Una capa de tipo `Embedding`\n",
    "2. Una capa de tipo `GlobalAveragePooling1D`\n",
    "3. Una capa de tipo `Dense` con 16 neuronas y activacion \"relu\"\n",
    "4. La capa de salida, de tipo `Dense` con una sola neurona (1 o 0, dos clasificaciones) y activacion \"sigmoid\" que retorna valores entre 0 y 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Capa de tipo `Embedding`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un problema que podemos encontrar cuando hacemos analisis de texto es ¿cómo hacer que nuestro modelo identifique palabras que tienen significados \"similares\"?\n",
    "\n",
    "Por ejemplo, si en nuestro diccionario tenemos que:\n",
    "```\n",
    "diccionario[\"bueno\"] == 4\n",
    "diccionario[\"excelente\"] == 22\n",
    "```\n",
    "Nosotros como personas podemos identificar que ambas palabras son similares, pero nuestros modelos las ven como 4 y 12, y no visualizan esta similitud.\n",
    "\n",
    "La capa de tipo `Embedding` transforma cada elemento del input (un numero que representa una palabra) en un vector positivo de N dimensiones.\n",
    "\n",
    "Recibe como parametro la cantidad de palabras del vocabulario utilizado (cantidad de palabras posibles) y genera un numero de pesos igual a la dimension a transformar por el tamaño del vocabulario.\n",
    "- De esta forma genera internamente una tabla donde cada palabra posible tendrá asociada un vector de N dimensiones dado por N de los pesos de la capa\n",
    "- Por ejemplo, para un vocabulario de tamaño 4 y transformando las palabras a vectores de 2 dimensiones se obtiene:\n",
    "| vocabulario | embedding |\n",
    "| :---------: | :-------: |\n",
    "| 0 | \\[w1, w2\\] |\n",
    "| 1 | \\[w3, w4\\] |\n",
    "| 2 | \\[w5, w6\\] |\n",
    "| 3 | \\[w7, w8\\] |\n",
    "\n",
    "Con estos nuevos parametros, se logra que, una vez optimizados, la codificacion de palabras con significados \"similares\" sea parecida.\n",
    "\n",
    "_[Excelente post sobre como funciona la capa **Embedding**](https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Capa de tipo `GlobalAveragePooling1D`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las capas de tipo `Pooling` reducen el numero de dimensiones del output de la capa anterior procurando mantener la informacion del mismo. Estas capas no agregan nuevos parametros para optimizar, ya que existen multiples estrategias predifinidas, como `Max` y `Average`, que se utilizan para conseguir este resultado.\n",
    "\n",
    "En particular `GlobalAveragePooling1D` convierte un output de 2 dimensiones a un vector de 1 dimensión calculando el promedio de cada vector que representa una palabra.\n",
    "- Ej si lo que recibe es `[[1,1], [1, 3], ..., [5, 3]]` lo convertirá en `[1, 2, ..., 4]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, las capas de `Encoding` y `Pooling` se encargan de procesar nuevamente nuestro diccionario generando una nueva codificación que contemplará una mayor cantidad de informacion como la similitud de significados entre palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente podemos contruir el modelo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          1417408   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,417,697\n",
      "Trainable params: 1,417,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(word_index)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocabulary_size, 16))  # Codificamos las palabras con vectores de 16 dimenciones\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observese en qué etapa estan enfocados la mayor parte de los parametros a optimizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos crear un conjunto de validación a partir del conjunto de entrenamiento. \n",
    "\n",
    "El conjunto de validacion es un conjunto de datos que no se utilizaran para entrenar el modelo. Difiere del conjunto de pruebas en que el primero se utiliza **durante** el entrenamiento para ir teniendo, con cada iteracion, una evaluación imparcial de la eficacia de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 15000\n"
     ]
    }
   ],
   "source": [
    "validation_data = padded_train_data[:10000]\n",
    "validation_target = train_target[:10000]\n",
    "\n",
    "final_train_data = padded_train_data[10000:]\n",
    "final_train_target = train_target[10000:]\n",
    "                                  \n",
    "print(len(final_train_data), len(final_train_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si podemos entrenar nuestro modelo utilizando el parametro `validation_data` para indicar nuestro conjunto de validacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo!\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    final_train_data, \n",
    "    final_train_target, \n",
    "    epochs=40, \n",
    "    batch_size=512, \n",
    "    validation_data=(validation_data, validation_target), \n",
    "    verbose=0  # No queremos que escriba nada ya que ocuparia toda la pantalla (40 epochs)\n",
    ")\n",
    "\n",
    "print(\"Listo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `batch_size`: en cada iteracion (epoch) el modelo no necesariamente debe iterar sobre todos los datos de entrenamiento. Podemos hace que utilice, cada vez, un subconjunto random de tamaño reducido para asi hacer mas rapido el entrenamiento. El *batch size*, entonces, es el tamaño que se va a utilizar para dichos subconjuntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como definimos el parametro `verbose` en 0, no podemos ver el progreso del modelo con cada iteración. Pero el metodo `fit()` retorna un objeto de tipo `History` que contiene un diccionario con los valores de las metricas en cada iteracion del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a esto, podemos obtener una representacion visual de la evolución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "n_epochs = len(history_dict[\"acc\"])\n",
    "epochs = np.arange(1, n_epochs+1)\n",
    "\n",
    "# Graficamos las metricas del conjunto de entrenamiento\n",
    "plt.plot(epochs, history_dict[\"acc\"], \"b\", label=\"entrenamiento\")\n",
    "\n",
    "# Graficamos las metricas del conjunto de validacion\n",
    "plt.plot(epochs, history_dict[\"val_acc\"], label=\"validacion\")\n",
    "\n",
    "plt.title(\"Precision de entrenamiento y validacion\")\n",
    "plt.xlabel(\"Iteraciones\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente probamos la precision de nuestro modelo utilizando el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 682us/step - loss: 0.3284 - acc: 0.8713\n",
      "Precisión: 87.13%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(padded_test_data, test_target)\n",
    "print(f\"Precisión: {round(results[1]*100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
